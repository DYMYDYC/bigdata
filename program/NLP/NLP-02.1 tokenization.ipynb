{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[',\n",
       " 'Moby',\n",
       " 'Dick',\n",
       " 'by',\n",
       " 'Herman',\n",
       " 'Melville',\n",
       " '1851',\n",
       " ']',\n",
       " 'ETYMOLOGY',\n",
       " '.',\n",
       " '(',\n",
       " 'Supplied',\n",
       " 'by',\n",
       " 'a',\n",
       " 'Late',\n",
       " 'Consumptive',\n",
       " 'Usher',\n",
       " 'to',\n",
       " 'a',\n",
       " 'Grammar',\n",
       " 'School',\n",
       " ')']"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md = nltk.corpus.gutenberg.words(\"melville-moby_dick.txt\")\n",
    "md[:22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moby\n",
      "Dick\n",
      "by\n",
      "Herman\n",
      "Melville\n",
      "ETYMOLOGY\n",
      "Supplied\n",
      "by\n",
      "a\n",
      "Late\n",
      "Consumptive\n",
      "Usher\n",
      "to\n",
      "a\n",
      "Grammar\n",
      "School\n"
     ]
    }
   ],
   "source": [
    "for word in md[:22]:\n",
    "    if word.isalpha():\n",
    "        print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "moby\n",
      "dick\n",
      "by\n",
      "herman\n",
      "melville\n",
      "1851\n",
      "]\n",
      "etymology\n",
      ".\n",
      "(\n",
      "supplied\n",
      "by\n",
      "a\n",
      "late\n",
      "consumptive\n",
      "usher\n",
      "to\n",
      "a\n",
      "grammar\n",
      "school\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "for word in md[:22]:\n",
    "    print(word.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"The boy's cars aren't different colors.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WhitespaceTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', \"boy's\", 'cars', \"aren't\", 'different', 'colors.']\n",
      "['the', \"boy's\", 'cars', \"aren't\", 'different', 'colors.']\n",
      "['the', 'cars', 'different']\n"
     ]
    }
   ],
   "source": [
    "tokens = nltk.tokenize.WhitespaceTokenizer().tokenize(text)\n",
    "print(tokens)\n",
    "tokens_lower = [word.lower() for word in tokens ]\n",
    "print(tokens_lower)\n",
    "tokens_lower_isalpha = [word.lower() for word in tokens if word.isalpha()]\n",
    "print(tokens_lower_isalpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'boy', \"'s\", 'cars', 'are', \"n't\", 'different', 'colors', '.']\n",
      "['the', 'boy', \"'s\", 'cars', 'are', \"n't\", 'different', 'colors', '.']\n",
      "['the', 'boy', 'cars', 'are', 'different', 'colors']\n"
     ]
    }
   ],
   "source": [
    "tokens = nltk.word_tokenize(text)\n",
    "print(tokens)\n",
    "tokens_lower = [word.lower() for word in tokens ]\n",
    "print(tokens_lower)\n",
    "tokens_lower_isalpha = [word.lower() for word in tokens if word.isalpha()]\n",
    "print(tokens_lower_isalpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cat', 'cats', 'lie', 'lying', 'run', 'running', 'city', 'cities', 'month', 'monthly', 'woman', 'women']\n",
      "cat    >   cat\n",
      "cats    >   cat\n",
      "lie    >   lie\n",
      "lying    >   lie\n",
      "run    >   run\n",
      "running    >   run\n",
      "city    >   citi\n",
      "cities    >   citi\n",
      "month    >   month\n",
      "monthly    >   monthli\n",
      "woman    >   woman\n",
      "women    >   women\n"
     ]
    }
   ],
   "source": [
    "porter = nltk.PorterStemmer()\n",
    "my_list = [\"cat\",\"cats\",\"lie\",\"lying\",\"run\",\"running\",\"city\",\"cities\",\"month\",\"monthly\",\"woman\",\"women\"]\n",
    "print (my_list)\n",
    "for word in my_list:\n",
    "    print (word,\"   >  \",porter.stem(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LancasterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['eats', 'cats', 'lie', 'lying', 'run', 'running', 'city', 'cities', 'month', 'monthly', 'woman', 'women']\n",
      "eats    >   eat\n",
      "cats    >   cat\n",
      "lie    >   lie\n",
      "lying    >   lying\n",
      "run    >   run\n",
      "running    >   run\n",
      "city    >   city\n",
      "cities    >   city\n",
      "month    >   mon\n",
      "monthly    >   month\n",
      "woman    >   wom\n",
      "women    >   wom\n"
     ]
    }
   ],
   "source": [
    "lancaster = nltk.LancasterStemmer()\n",
    "my_list = [\"eats\",\"cats\",\"lie\",\"lying\",\"run\",\"running\",\"city\",\"cities\",\"month\",\"monthly\",\"woman\",\"women\"]\n",
    "print (my_list)\n",
    "for word in my_list:\n",
    "    print (word,\"   >  \",lancaster.stem(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feet    ->    foot\n",
      "cats    ->    cat\n",
      "wolves    ->    wolf\n",
      "lying    ->    lying\n",
      "run    ->    run\n",
      "running    ->    running\n",
      "city    ->    city\n",
      "cities    ->    city\n",
      "month    ->    month\n",
      "monthly    ->    monthly\n",
      "woman    ->    woman\n",
      "women    ->    woman\n"
     ]
    }
   ],
   "source": [
    "wnlem = nltk.WordNetLemmatizer()\n",
    "my_list = [\"feet\",\"cats\",\"wolves\",\"lying\",\"run\",\"running\",\"city\",\"cities\",\"month\",\"monthly\",\"woman\",\"women\"]\n",
    "for word in my_list:\n",
    "    print(word, \"   ->   \", wnlem.lemmatize(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
